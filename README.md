# BayeSmith-artifact

## Introduction

Static analyzers have burdened developer rather than helping because of too many false warnings.

In previous work, we developed Bingo (PLDI 2018), where we effectively improved the accuracy of a static analyzer with an interactive alarm prioritization system.

Bingo constructs a Bayesian network from the analysis results, and ranks the alarms according to their probabilities.

The programmer uses the system over a sequence of rounds: in each round, they look at the ranked list generated by Bingo, triage a set of alarms (usually just the first alarm in the list), and give feedback to the system.

In response, Bingo computes conditional probabilities given this feedback, and reranks the remaining alarms.

Through this process, we showed that the user is able to discover bugs much faster than they could otherwise have found them.

Although the original system substantially reduced the number of alarms under developers' investigation to find every bugs, we have found a fundamental limitations in the underlying Bayesian network.

In this paper, we develop BayeSmtih, a system which uses a database of program and its bug labels to learn Bayesian structure (both rule and weight) that improves the ranking and interactions by Bingo.

This artifact contains all data and programs required to run the experiments reported in the paper.

## Summary of Experimental Results

1. We have applied BayeSmith from 20 Unix programs (11 buffer-overflow + 9 format string analysis).
Each program has a set of known bugs. See Table 1.

2. Major experimental results are in Table 2-5, Figure 5-6:

    - Table 2: Comparing BayeSmith with Bingo as a baseline, together with various forms of learned Bayesian network.
    - Figure 5: Applying BayeSmith to the other applications that use Bayesin network as an underlying model.
    - Figure 6: Comparing BayeSmith's alarm ranking performance compared to Bingo. For entire benchmarks, see `~/rank-plots` directory.
    - Table 3: Measurement of how BayeSmith reduces the false generalizations over static analysis alarms compared to Bingo.
    - Table 4: Comparing the performance of BayeSmith with different training set.
    - Table 5: Measurement of how the learned model by BayeSmith scales in network size and inference time.

### System Requirements

To run the experiments that were reported in the paper, we used a 64-core (Intel Xeon Processor Gold 6226R, 2.90 Ghz) machine with 128 GB of RAM with the 20.04 version of Ubuntu Linux. We recommend to run the experiments with at least 10-core machine with 32 GB of RAM.

### Directory Structure

#### `~/datalog` - Learned rules (Datalog)

Pre-learned rules can be found here.

1. `BufferOverflow.dl` and `IntegerOverflow.dl` are the **initial** rules used for interval analysis and taint analysis, respectively.
2. `BufferOverflow.<PROGRAM>.dl` and `IntegerOverflow.<PROGRAM>.dl` are the **learned** rule for `<PROGRAM>`, which is one of the benchmarks starting from *1*.
3. `TBufferOverflow.<PROGRAM>.dl` and `TIntegerOverflow.<PROGRAM>.dl` are the **modified** version of learned rules(*2*) in a way that considering feedback from dynamic instrumentation.

#### `~/rank-plots` - Rank plots

Every plot showing the change of true bug ranking(*Y*) over the interactions(*X*) for each program can be found in `rank-plots` directory. `<PROGRAM>.pdf` is the plot for `<PROGRAM>`.

#### `~/bayesmith/bingo` - Main implementations

The implementaion for Bayesian struture learning algorithm together with the modified version of Bayesian alarm ranking system are here.

- `*/src`: Main program for learning algorithm (e.g. `learn.ml`, `bNet.ml`, `datalog.ml`)
- `*.py`, `*/prune-cons`: Bayesian alarm ranking system (Modified version of Bingo, PLDI 2018)

#### `~/bayesmith/bin` - Main scripts

- `run.py`: Analyze (Sparrow) and rank (Bingo) a program
- `plot.sh`: Plot rank changes comparison between before and after the learning procedure for benchmarks (Figure XX)

#### `~/bayesmith/script` - Debug scripts

#### `~/bayesmith/benchmarks` - Benchmarks

#### `~/dynaboost` - Implementation for DynaBoost (FSE 2021)

#### `~/drake` - Implementation for Drake (PLDI 2019)

Programs used for evaluation can be found here.

- `*/<PROGRAM>/<VERSION>/sparrow/*.c`: Program source code
- `*/<PROGRAM>/<VERSION>/label.json`: Bug label for the program


## Launch

To build BayeSmith docker image, run below command:

```sh
docker build . -t bayesmith --shm-size 4G
```

To launch the docker container, run below command:

```sh
docker run -it bayesmith
```

DockerFile itself manages to build `DynaBoost` and `Drake`.
For now, one should manually git-clone the [BayeSmith repository](https://github.com/prosyslab/continuous-reasoning.git), then build.

```sh
cd ~
git clone https://github.com/prosyslab/continuous-reasoning.git bayesmith
cd bayesmith
./build.sh
```

One may do the following to build BayeSmith:

- delete `opam install depext` from `sparrow`, then change `opam depext ...` to `opam install --depext-only ...`
- install `clang` using [`install-llvm-toolchain.sh`](https://github.com/prosyslab/sysadmin/blob/master/install-llvm-toolchain.sh)

## Run

### Learn

```sh
$ cd ~/bayesmith
$ bingo/learn -reuse -analysis_type [ interval | taint ] -debug $BENCH_NAME
```

e.g. `bingo/learn -reuse -analysis_type interval -debug sort`

Logs (`learn.log`) and output (`.dl` file) will be generated under `learn-out` directory.
One may change the name of the directory with option `-out_dir $DIRNAME`.

### Test

```sh
$ bingo/learn -test -analysis_type [ interval | taint ] -out_dir test-out $BENCH_NAME
```

e.g. `bingo/learn -test -analysis_type interval -out_dir test-out -dl_from $PATH_TO_DL_FILE sort`

Logs (`learn.log`) and output (`.dl` file) will be generated under `test-out` directory (by default).
One may run test with existing datalog rule file with option `-dl_from $PATH_TO_DATALOG_FILE`.
One may run test with custom rule weights with option `-rule_prob_from $PATH_TO_RULE_PROB_TXT_FILE`.
One may change the name of the directory with option `-out_dir $DIRNAME`.
One may give a timestamp with optipn `-timestamp`.

### Report (figures)

```sh
$ cd bayesmith
$ ./script/plot.sh <BINGO_TIMESTAMP> <BAYESMITH_TIMESTAMP> -p   # Figure 6
$ ./bar-plot.sh   # Figure 5
```
